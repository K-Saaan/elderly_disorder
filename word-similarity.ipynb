{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec(CBOW, Skip-gram), GloVe를 사용해 단어들의 유사도 확인 비교 모델 베이스라인 작성 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!pip install glove-python-binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T02:20:25.997214Z",
     "start_time": "2024-04-10T02:20:08.863441Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from glove import Corpus, Glove\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./단어사전/disorder_token_sangjin.pkl', 'rb') as f:\n",
    "    tokens = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'주의'와(과) 유사한 단어들:\n",
      "임무: 0.3143480122089386\n",
      "운동: 0.25495392084121704\n",
      "동안: 0.24983598291873932\n",
      "비행: 0.23560838401317596\n",
      "활동: 0.22014707326889038\n"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(tokens.values(), vector_size=100, window=5, min_count=1, sg=0)\n",
    "\n",
    "word1 = \"주의\"\n",
    "\n",
    "similar_words = model.wv.most_similar(word1, topn=5)\n",
    "\n",
    "print(f\"'{word1}'와(과) 유사한 단어들:\")\n",
    "for word, similarity in similar_words:\n",
    "    print(f\"{word}: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip-gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample-Example similarity: 0.2884923219680786\n"
     ]
    }
   ],
   "source": [
    "# Skip-gram 모델 훈련\n",
    "skipgram_model = Word2Vec(tokens.values(), vector_size=100, window=5, min_count=1, workers=4, sg=1)\n",
    "\n",
    "# 단어 유사도 계산\n",
    "similarity = skipgram_model.wv.similarity('주의', '활동')\n",
    "print(f\"Sample-Example similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 30 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Words similar to '집중력': [('시작', 0.37474681930448084), ('참여', 0.2798269753093418), ('휴대', 0.2720635181098524), ('양식', 0.2401908446687907), ('쇼핑', 0.23388976725801533), ('관계', 0.22760232135279784), ('지향', 0.21636718687754952), ('지갑', 0.21214355773878119), ('느낌', 0.1849278445299922)]\n"
     ]
    }
   ],
   "source": [
    "# 코퍼스 생성 및 모델 훈련\n",
    "corpus = Corpus()\n",
    "corpus.fit(tokens.values(), window=10)\n",
    "glove = Glove(no_components=100, learning_rate=0.05)\n",
    "glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n",
    "glove.add_dictionary(corpus.dictionary)\n",
    "\n",
    "# 단어 유사도 계산\n",
    "word = '집중력'\n",
    "similar_words = glove.most_similar(word, number=10)\n",
    "print(f\"Words similar to '{word}': {similar_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### klue/bert-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델과 토크나이저 로드\n",
    "model_name = \"klue/bert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_word_embedding(word, tokenizer, model):\n",
    "    # 단어를 문장에 포함시켜 토큰화 (여기서는 단어 자체를 문장으로 가정)\n",
    "    inputs = tokenizer(word, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    # 모델을 통해 텍스트의 임베딩을 얻음\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 첫 번째 토큰([CLS] 토큰)의 임베딩을 제외하고, 단어에 해당하는 토큰의 임베딩 평균 계산\n",
    "    hidden_states = outputs.last_hidden_state[:, 1:-1, :]  # [CLS]와 [SEP] 토큰을 제외\n",
    "    word_embedding = torch.mean(hidden_states, dim=1)\n",
    "    \n",
    "    return word_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cosine_similarity(word1, word2):\n",
    "    word1_embedding = get_word_embedding(word1, tokenizer, model)\n",
    "    word2_embedding = get_word_embedding(word2, tokenizer, model)\n",
    "\n",
    "    similarity = cosine_similarity(word1_embedding, word2_embedding)\n",
    "\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.7181])\n"
     ]
    }
   ],
   "source": [
    "print(get_cosine_similarity(\"사과\", \"바나나\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "def tsne_plot_similar_words(model, labels, top_n=30):\n",
    "\n",
    "    embedding_clusters = []\n",
    "    word_clusters = []\n",
    "    for word in labels:\n",
    "        embeddings = []\n",
    "        words = []\n",
    "\n",
    "        for similar_word, _ in model.wv.most_similar(word, topn=top_n):\n",
    "            words.append(similar_word)\n",
    "            embeddings.append(model.wv[similar_word])\n",
    "        embedding_clusters.append(embeddings)\n",
    "        word_clusters.append(words)\n",
    "\n",
    "    embedding_clusters = np.array(embedding_clusters)\n",
    "\n",
    "    n, m, k = embedding_clusters.shape\n",
    "    tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=42)\n",
    "    embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    \n",
    "    for label, embeddings, words, color in zip(labels, embeddings_en_2d, word_clusters, colors):\n",
    "        x = embeddings[:, 0]\n",
    "        y = embeddings[:, 1]\n",
    "        plt.scatter(x, y, c=color, alpha=0.7, label=label)\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),\n",
    "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
    "            \n",
    "    plt.legend(loc=4)\n",
    "    plt.xlabel(\"dimension 1\")\n",
    "    plt.ylabel(\"dimension 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
