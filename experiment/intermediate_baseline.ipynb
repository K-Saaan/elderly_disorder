{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import json\n",
    "import datetime\n",
    "import platform\n",
    "from tqdm import tqdm\n",
    "import datasets\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import gc\n",
    "\n",
    "from transformers import BertConfig, BertModel, BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup, Trainer, TrainingArguments, DataCollatorWithPadding, DataCollatorForLanguageModeling\n",
    "from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, AdamW, AutoModelForCausalLM, BitsAndBytesConfig, AutoModelForMaskedLM\n",
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, RandomSampler, SequentialSampler\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, \\\n",
    "                            roc_auc_score, confusion_matrix, classification_report, \\\n",
    "                            matthews_corrcoef, cohen_kappa_score, log_loss, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os_name = platform.system()\n",
    "if os_name == 'Darwin' :  # MacOS \n",
    "    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "elif os_name == 'Windows' :\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "else :\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_df(file_path):\n",
    "#     records = []\n",
    "#     with open(file_path, 'r') as f:\n",
    "#         json_data = json.load(f)\n",
    "#     for entry in json_data['data']:\n",
    "#         record = {\n",
    "#             'book_id': entry['book_id'],\n",
    "#             'category': entry['category'],\n",
    "#             'popularity': entry['popularity'],\n",
    "#             'text': entry['text'],\n",
    "#             'word_segment': entry['word_segment'],\n",
    "#             'publication_ymd': entry['publication_ymd']\n",
    "#         }\n",
    "#         records.append(record)\n",
    "        \n",
    "#     return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '../data/intermediate/Training_medical.json'\n",
    "# df = convert_df(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mental_df = df[df['category']=='정신과학']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txtToDf(path):\n",
    "    with open(path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # # 각 줄에서 불필요한 공백과 쉼표를 제거하고 리스트로 저장\n",
    "    add = [line.strip().rstrip(',') for line in lines]\n",
    "    return pd.DataFrame(add, columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여기부터 실행\n",
    "mental1 = pd.read_csv('../data/intermediate/mental1.csv') # 의료 전문서적 말뭉치\n",
    "mental2 = txtToDf('../data/intermediate/mental2.txt')     # DSM-5 \n",
    "mental3 = txtToDf('../data/intermediate/mental3.txt')     # 국가건강정보포털 말뭉치\n",
    "mental4 = pd.read_csv('../data/intermediate/mental4.csv') # 전문분야 한영 말뭉치"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 모델 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 ID 선언\n",
    "model_id = \"snunlp/KR-BERT-char16424\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForMaskedLM.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, eval_df = train_test_split(df, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.Dataset.from_pandas(train_df[['text']])\n",
    "eval_dataset = datasets.Dataset.from_pandas(eval_df[['text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(samples):\n",
    "    tokens = tokenizer(samples['text'], truncation=True, padding='max_length', max_length=512)\n",
    "    return tokens\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenize_function)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 설정\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results/intermediate\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=3e-4,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    report_to=[\"tensorboard\"],\n",
    "    num_train_epochs=200,\n",
    "    logging_steps=20,\n",
    "    weight_decay=0.05,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "# Trainer 정의\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False\n",
    "result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model = trainer.model\n",
    "torch.save(intermediate_model.state_dict(), './model/mental_intertxt_dsm/intermediate_model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./model/mental_intertxt_dsm/intermediate_model\")\n",
    "tokenizer.save_pretrained(\"./model/mental_intertxt_dsm/intermediate_model/tokenize\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
